{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# 라이브러리 사용\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506, 1)\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# 1.과거의 데이터를 준비합니다.\n",
    "파일경로 = 'https://raw.githubusercontent.com/blackdew/tensorflow1/master/csv/boston.csv'\n",
    "보스턴 = pd.read_csv(파일경로)\n",
    " \n",
    "# 종속변수, 독립변수\n",
    "독립 = 보스턴[['crim', 'zn', 'indus', 'chas', 'nox', \n",
    "            'rm', 'age', 'dis', 'rad', 'tax',\n",
    "            'ptratio', 'b', 'lstat']]\n",
    "종속 = 보스턴[['medv']]\n",
    "print(독립.shape, 종속.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# 2. 모델의 구조를 만듭니다\n",
    "X = tf.keras.layers.Input(shape=[13])\n",
    "H = tf.keras.layers.Dense(10, activation='swish')(X)\n",
    "Y = tf.keras.layers.Dense(1)(H)\n",
    "model = tf.keras.models.Model(X, Y)\n",
    "model.compile(loss='mse')\n",
    " \n",
    "# 모델 구조 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.6144\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - 0s 666us/step - loss: 31.7739\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.7990\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.7373\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 28.5315\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 30.3834\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 32.2332\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.9202\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.7865\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.4415\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 30.0110\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 30.0261\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 30.5391\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 29.9382\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.8509\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 28.4571\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - 0s 632us/step - loss: 31.8615\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 28.7865\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.8211\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 32.2785\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.1845\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.8422\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.1373\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.4771\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 28.2711\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 30.4630\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 30.2900\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 28.0280\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 30.6811\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.7719\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 28.9588\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 30.2144\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 30.4912\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 30.2781\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 30.9044\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.0110\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 30.3659\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.2706\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 28.8725\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - 0s 732us/step - loss: 30.7549\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.0452\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.1671\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 30.7427\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.8196\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.1046\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.8338\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 31.3613\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.2694\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 30.2768\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 28.4755\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.6334\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.2649\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 30.0760\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.3986\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.3428\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 28.0444\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 47.81 - 0s 466us/step - loss: 30.8520\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.2398\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - 0s 650us/step - loss: 31.7226\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 29.0030\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 30.7685\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.2085\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.4351\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 30.0329\n",
      "Epoch 65/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 28.1523\n",
      "Epoch 66/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.3217\n",
      "Epoch 67/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 28.7334\n",
      "Epoch 68/1000\n",
      "16/16 [==============================] - 0s 655us/step - loss: 29.5446\n",
      "Epoch 69/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 27.4855\n",
      "Epoch 70/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 30.5655\n",
      "Epoch 71/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.3209\n",
      "Epoch 72/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.8192\n",
      "Epoch 73/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.2695\n",
      "Epoch 74/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 30.2915\n",
      "Epoch 75/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 31.1899\n",
      "Epoch 76/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.1995\n",
      "Epoch 77/1000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 31.2507\n",
      "Epoch 78/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.2342\n",
      "Epoch 79/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.2900\n",
      "Epoch 80/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 31.0207\n",
      "Epoch 81/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.6732\n",
      "Epoch 82/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.1009\n",
      "Epoch 83/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.6181\n",
      "Epoch 84/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.7507\n",
      "Epoch 85/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.8605\n",
      "Epoch 86/1000\n",
      "16/16 [==============================] - 0s 713us/step - loss: 28.5783\n",
      "Epoch 87/1000\n",
      "16/16 [==============================] - 0s 664us/step - loss: 29.8550\n",
      "Epoch 88/1000\n",
      "16/16 [==============================] - 0s 691us/step - loss: 27.7876\n",
      "Epoch 89/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 29.9972\n",
      "Epoch 90/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 28.4391\n",
      "Epoch 91/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 28.9374\n",
      "Epoch 92/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 30.4154\n",
      "Epoch 93/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.7658\n",
      "Epoch 94/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 28.9486\n",
      "Epoch 95/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.7735\n",
      "Epoch 96/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.9480\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 665us/step - loss: 29.0144\n",
      "Epoch 98/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 28.0433\n",
      "Epoch 99/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 28.5563\n",
      "Epoch 100/1000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 30.6168\n",
      "Epoch 101/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.7141\n",
      "Epoch 102/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.0486\n",
      "Epoch 103/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 29.5021\n",
      "Epoch 104/1000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 28.3801\n",
      "Epoch 105/1000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 28.3027\n",
      "Epoch 106/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 28.1408\n",
      "Epoch 107/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 30.7532\n",
      "Epoch 108/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.3163\n",
      "Epoch 109/1000\n",
      "16/16 [==============================] - 0s 774us/step - loss: 27.0204\n",
      "Epoch 110/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 29.9527\n",
      "Epoch 111/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.5472\n",
      "Epoch 112/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.9299\n",
      "Epoch 113/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.4499\n",
      "Epoch 114/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.8144\n",
      "Epoch 115/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.7891\n",
      "Epoch 116/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.4997\n",
      "Epoch 117/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 27.9834\n",
      "Epoch 118/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 30.1795\n",
      "Epoch 119/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.6341\n",
      "Epoch 120/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.0697\n",
      "Epoch 121/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.9182\n",
      "Epoch 122/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 28.1446\n",
      "Epoch 123/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.5821\n",
      "Epoch 124/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.9712\n",
      "Epoch 125/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.2629\n",
      "Epoch 126/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.7144\n",
      "Epoch 127/1000\n",
      "16/16 [==============================] - 0s 502us/step - loss: 28.0541\n",
      "Epoch 128/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 28.1544\n",
      "Epoch 129/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.6765\n",
      "Epoch 130/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 28.7713\n",
      "Epoch 131/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 29.3955\n",
      "Epoch 132/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.2824\n",
      "Epoch 133/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 28.2553\n",
      "Epoch 134/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.2622\n",
      "Epoch 135/1000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 27.4989\n",
      "Epoch 136/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 28.4820\n",
      "Epoch 137/1000\n",
      "16/16 [==============================] - 0s 755us/step - loss: 28.4821\n",
      "Epoch 138/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 28.2778\n",
      "Epoch 139/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.7036\n",
      "Epoch 140/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.2840\n",
      "Epoch 141/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 30.2699\n",
      "Epoch 142/1000\n",
      "16/16 [==============================] - 0s 463us/step - loss: 28.6271\n",
      "Epoch 143/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.9874\n",
      "Epoch 144/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.7723\n",
      "Epoch 145/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.0390\n",
      "Epoch 146/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.5367\n",
      "Epoch 147/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.0036\n",
      "Epoch 148/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 32.3936\n",
      "Epoch 149/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.1588\n",
      "Epoch 150/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.8354\n",
      "Epoch 151/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.5652\n",
      "Epoch 152/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 28.3082\n",
      "Epoch 153/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.2647\n",
      "Epoch 154/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.2426\n",
      "Epoch 155/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.8551\n",
      "Epoch 156/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.8107\n",
      "Epoch 157/1000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 28.2710\n",
      "Epoch 158/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.2428\n",
      "Epoch 159/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.9835\n",
      "Epoch 160/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.2839\n",
      "Epoch 161/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 30.7438\n",
      "Epoch 162/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.3267\n",
      "Epoch 163/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.6894\n",
      "Epoch 164/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.3092\n",
      "Epoch 165/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.8157\n",
      "Epoch 166/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.3240\n",
      "Epoch 167/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.1484\n",
      "Epoch 168/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 28.7663\n",
      "Epoch 169/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.6975\n",
      "Epoch 170/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 28.4203\n",
      "Epoch 171/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 28.3073\n",
      "Epoch 172/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.8556\n",
      "Epoch 173/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.0961\n",
      "Epoch 174/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.1376\n",
      "Epoch 175/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.5669\n",
      "Epoch 176/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.1283\n",
      "Epoch 177/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.7651\n",
      "Epoch 178/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 29.2749\n",
      "Epoch 179/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.5023\n",
      "Epoch 180/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.9041\n",
      "Epoch 181/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 28.3734\n",
      "Epoch 182/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.5180\n",
      "Epoch 183/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.2560\n",
      "Epoch 184/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 16.78 - 0s 532us/step - loss: 28.1409\n",
      "Epoch 185/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.9799\n",
      "Epoch 186/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.5897\n",
      "Epoch 187/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 27.7560\n",
      "Epoch 188/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.5064\n",
      "Epoch 189/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.2704\n",
      "Epoch 190/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 29.6699\n",
      "Epoch 191/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.4714\n",
      "Epoch 192/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 598us/step - loss: 27.3377\n",
      "Epoch 193/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.5967\n",
      "Epoch 194/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 27.3184\n",
      "Epoch 195/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 28.0859\n",
      "Epoch 196/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.7828\n",
      "Epoch 197/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.6973\n",
      "Epoch 198/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.7179\n",
      "Epoch 199/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.0251\n",
      "Epoch 200/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.8620\n",
      "Epoch 201/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.5560\n",
      "Epoch 202/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.6242\n",
      "Epoch 203/1000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 28.9984\n",
      "Epoch 204/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.3887\n",
      "Epoch 205/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.0882\n",
      "Epoch 206/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.9074\n",
      "Epoch 207/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.9185\n",
      "Epoch 208/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 27.5281\n",
      "Epoch 209/1000\n",
      "16/16 [==============================] - 0s 400us/step - loss: 26.7586\n",
      "Epoch 210/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.9179\n",
      "Epoch 211/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.7954\n",
      "Epoch 212/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.3099\n",
      "Epoch 213/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.1974\n",
      "Epoch 214/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.4132\n",
      "Epoch 215/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.3000\n",
      "Epoch 216/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 22.69 - 0s 465us/step - loss: 27.2026\n",
      "Epoch 217/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.0147\n",
      "Epoch 218/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.8661\n",
      "Epoch 219/1000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 27.8993\n",
      "Epoch 220/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.9534\n",
      "Epoch 221/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.1578\n",
      "Epoch 222/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 28.5860\n",
      "Epoch 223/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.9720\n",
      "Epoch 224/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 28.5818\n",
      "Epoch 225/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.4191\n",
      "Epoch 226/1000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 27.3640\n",
      "Epoch 227/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 28.6072\n",
      "Epoch 228/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.8105\n",
      "Epoch 229/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.6688\n",
      "Epoch 230/1000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 27.1938\n",
      "Epoch 231/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.1432\n",
      "Epoch 232/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 29.2627\n",
      "Epoch 233/1000\n",
      "16/16 [==============================] - 0s 634us/step - loss: 26.8993\n",
      "Epoch 234/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.2607\n",
      "Epoch 235/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.5122\n",
      "Epoch 236/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.3170\n",
      "Epoch 237/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.1608\n",
      "Epoch 238/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.1049\n",
      "Epoch 239/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 31.2229\n",
      "Epoch 240/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.9900\n",
      "Epoch 241/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.0911\n",
      "Epoch 242/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.0485\n",
      "Epoch 243/1000\n",
      "16/16 [==============================] - 0s 495us/step - loss: 27.2451\n",
      "Epoch 244/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.2099\n",
      "Epoch 245/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.1238\n",
      "Epoch 246/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 29.3322\n",
      "Epoch 247/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 29.0870\n",
      "Epoch 248/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.9860\n",
      "Epoch 249/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.7213\n",
      "Epoch 250/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.4845\n",
      "Epoch 251/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.1936\n",
      "Epoch 252/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.4966\n",
      "Epoch 253/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.0751\n",
      "Epoch 254/1000\n",
      "16/16 [==============================] - 0s 500us/step - loss: 26.9969\n",
      "Epoch 255/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 29.7189\n",
      "Epoch 256/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.4259\n",
      "Epoch 257/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.9583\n",
      "Epoch 258/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.9465\n",
      "Epoch 259/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.2601\n",
      "Epoch 260/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.3022\n",
      "Epoch 261/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.9192\n",
      "Epoch 262/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.7821\n",
      "Epoch 263/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.5536\n",
      "Epoch 264/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.2143\n",
      "Epoch 265/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.2714\n",
      "Epoch 266/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.3898\n",
      "Epoch 267/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.9463\n",
      "Epoch 268/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.6870\n",
      "Epoch 269/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.9205\n",
      "Epoch 270/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.9522\n",
      "Epoch 271/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.5541\n",
      "Epoch 272/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.1705\n",
      "Epoch 273/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 28.9716\n",
      "Epoch 274/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.5202\n",
      "Epoch 275/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.7347\n",
      "Epoch 276/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 28.3082\n",
      "Epoch 277/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.0984\n",
      "Epoch 278/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.7784\n",
      "Epoch 279/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.3684\n",
      "Epoch 280/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 26.2056\n",
      "Epoch 281/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.0107\n",
      "Epoch 282/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.8936\n",
      "Epoch 283/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 26.9843\n",
      "Epoch 284/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.0074\n",
      "Epoch 285/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.8775\n",
      "Epoch 286/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.2267\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 532us/step - loss: 26.3783\n",
      "Epoch 288/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.7791\n",
      "Epoch 289/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.7770\n",
      "Epoch 290/1000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 26.2842\n",
      "Epoch 291/1000\n",
      "16/16 [==============================] - 0s 464us/step - loss: 26.5374\n",
      "Epoch 292/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.9557\n",
      "Epoch 293/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.5486\n",
      "Epoch 294/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.1457\n",
      "Epoch 295/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.5970\n",
      "Epoch 296/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.2117\n",
      "Epoch 297/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.2636\n",
      "Epoch 298/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.1904\n",
      "Epoch 299/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.3430\n",
      "Epoch 300/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.0275\n",
      "Epoch 301/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.7105\n",
      "Epoch 302/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 29.8388\n",
      "Epoch 303/1000\n",
      "16/16 [==============================] - 0s 399us/step - loss: 25.8829\n",
      "Epoch 304/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.6785\n",
      "Epoch 305/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.6559\n",
      "Epoch 306/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.5571\n",
      "Epoch 307/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.8366\n",
      "Epoch 308/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.3494\n",
      "Epoch 309/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.9199\n",
      "Epoch 310/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 28.6250\n",
      "Epoch 311/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.3572\n",
      "Epoch 312/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.2466\n",
      "Epoch 313/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.2454\n",
      "Epoch 314/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 27.6499\n",
      "Epoch 315/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.3166\n",
      "Epoch 316/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 29.7955\n",
      "Epoch 317/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.0552\n",
      "Epoch 318/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.8943\n",
      "Epoch 319/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.4699\n",
      "Epoch 320/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.9896\n",
      "Epoch 321/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.6922\n",
      "Epoch 322/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.1964\n",
      "Epoch 323/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.4992\n",
      "Epoch 324/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 26.8939\n",
      "Epoch 325/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.8874\n",
      "Epoch 326/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.0326\n",
      "Epoch 327/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.6800\n",
      "Epoch 328/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.2590\n",
      "Epoch 329/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.1817\n",
      "Epoch 330/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.2366\n",
      "Epoch 331/1000\n",
      "16/16 [==============================] - 0s 666us/step - loss: 27.8138\n",
      "Epoch 332/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.5416\n",
      "Epoch 333/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.8480\n",
      "Epoch 334/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.1081\n",
      "Epoch 335/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.5900\n",
      "Epoch 336/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.8441\n",
      "Epoch 337/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.1762\n",
      "Epoch 338/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.9847\n",
      "Epoch 339/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.0996\n",
      "Epoch 340/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.7272\n",
      "Epoch 341/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 28.0766\n",
      "Epoch 342/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.1225\n",
      "Epoch 343/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.8791\n",
      "Epoch 344/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.5121\n",
      "Epoch 345/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.2896\n",
      "Epoch 346/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 26.8705\n",
      "Epoch 347/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 27.2822\n",
      "Epoch 348/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.6854\n",
      "Epoch 349/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.3372\n",
      "Epoch 350/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.3088\n",
      "Epoch 351/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.9534\n",
      "Epoch 352/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.1677\n",
      "Epoch 353/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.8420\n",
      "Epoch 354/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.1758\n",
      "Epoch 355/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.1026\n",
      "Epoch 356/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.9730\n",
      "Epoch 357/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.2585\n",
      "Epoch 358/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.0862\n",
      "Epoch 359/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.2126\n",
      "Epoch 360/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 25.8041\n",
      "Epoch 361/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 29.3595\n",
      "Epoch 362/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.6053\n",
      "Epoch 363/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.0879\n",
      "Epoch 364/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.0406\n",
      "Epoch 365/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 28.2545\n",
      "Epoch 366/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.8535\n",
      "Epoch 367/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.8881\n",
      "Epoch 368/1000\n",
      "16/16 [==============================] - 0s 664us/step - loss: 27.8413\n",
      "Epoch 369/1000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 27.1604\n",
      "Epoch 370/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.3093\n",
      "Epoch 371/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.4221\n",
      "Epoch 372/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.4184\n",
      "Epoch 373/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 27.1832\n",
      "Epoch 374/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 29.3384\n",
      "Epoch 375/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.5890\n",
      "Epoch 376/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.2153\n",
      "Epoch 377/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 26.6207\n",
      "Epoch 378/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.9773\n",
      "Epoch 379/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.3546\n",
      "Epoch 380/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.2700\n",
      "Epoch 381/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.7593\n",
      "Epoch 382/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 532us/step - loss: 26.6489\n",
      "Epoch 383/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.1356\n",
      "Epoch 384/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.3016\n",
      "Epoch 385/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 29.1015\n",
      "Epoch 386/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.3720\n",
      "Epoch 387/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 26.9090\n",
      "Epoch 388/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.8650\n",
      "Epoch 389/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.7793\n",
      "Epoch 390/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.5280\n",
      "Epoch 391/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.8982\n",
      "Epoch 392/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 25.4234\n",
      "Epoch 393/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.3813\n",
      "Epoch 394/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.6156\n",
      "Epoch 395/1000\n",
      "16/16 [==============================] - 0s 704us/step - loss: 27.4130\n",
      "Epoch 396/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 27.4615\n",
      "Epoch 397/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.6598\n",
      "Epoch 398/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.6171\n",
      "Epoch 399/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 27.2819\n",
      "Epoch 400/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 28.7724\n",
      "Epoch 401/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.4229\n",
      "Epoch 402/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.5494\n",
      "Epoch 403/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.9411\n",
      "Epoch 404/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.9246\n",
      "Epoch 405/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.8276\n",
      "Epoch 406/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 26.9515\n",
      "Epoch 407/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.1090\n",
      "Epoch 408/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 28.5542\n",
      "Epoch 409/1000\n",
      "16/16 [==============================] - 0s 664us/step - loss: 26.7540\n",
      "Epoch 410/1000\n",
      "16/16 [==============================] - 0s 732us/step - loss: 27.3699\n",
      "Epoch 411/1000\n",
      "16/16 [==============================] - 0s 644us/step - loss: 25.9741\n",
      "Epoch 412/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.8599\n",
      "Epoch 413/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 28.5627\n",
      "Epoch 414/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.8111\n",
      "Epoch 415/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.8899\n",
      "Epoch 416/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 28.0588\n",
      "Epoch 417/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 29.1139\n",
      "Epoch 418/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 24.5549\n",
      "Epoch 419/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 28.9404\n",
      "Epoch 420/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.6373\n",
      "Epoch 421/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.9948\n",
      "Epoch 422/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.7289\n",
      "Epoch 423/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 29.1643\n",
      "Epoch 424/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.7867\n",
      "Epoch 425/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.9469\n",
      "Epoch 426/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.0291\n",
      "Epoch 427/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.0173\n",
      "Epoch 428/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.3200\n",
      "Epoch 429/1000\n",
      "16/16 [==============================] - 0s 660us/step - loss: 27.2269\n",
      "Epoch 430/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.9239\n",
      "Epoch 431/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.5872\n",
      "Epoch 432/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.3135\n",
      "Epoch 433/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.1910\n",
      "Epoch 434/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.8179\n",
      "Epoch 435/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 26.0591\n",
      "Epoch 436/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.8832\n",
      "Epoch 437/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.3500\n",
      "Epoch 438/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.4696\n",
      "Epoch 439/1000\n",
      "16/16 [==============================] - 0s 442us/step - loss: 28.0729\n",
      "Epoch 440/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.5494\n",
      "Epoch 441/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 26.6096\n",
      "Epoch 442/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 26.4528\n",
      "Epoch 443/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.0093\n",
      "Epoch 444/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 26.5879\n",
      "Epoch 445/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.5123\n",
      "Epoch 446/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 26.0552\n",
      "Epoch 447/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.8275\n",
      "Epoch 448/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.8420\n",
      "Epoch 449/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.5910\n",
      "Epoch 450/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.5939\n",
      "Epoch 451/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 25.9701\n",
      "Epoch 452/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.7371\n",
      "Epoch 453/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.1244\n",
      "Epoch 454/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.3322\n",
      "Epoch 455/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.5997\n",
      "Epoch 456/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.0961\n",
      "Epoch 457/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.2497\n",
      "Epoch 458/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.1372\n",
      "Epoch 459/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.0346\n",
      "Epoch 460/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.7857\n",
      "Epoch 461/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.8121\n",
      "Epoch 462/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.9117\n",
      "Epoch 463/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.8369\n",
      "Epoch 464/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.7927\n",
      "Epoch 465/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.9306\n",
      "Epoch 466/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.4996\n",
      "Epoch 467/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.2077\n",
      "Epoch 468/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.9971\n",
      "Epoch 469/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.9527\n",
      "Epoch 470/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 23.9723\n",
      "Epoch 471/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.6093\n",
      "Epoch 472/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.5377\n",
      "Epoch 473/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.8115\n",
      "Epoch 474/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.3671\n",
      "Epoch 475/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.7518\n",
      "Epoch 476/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.9479\n",
      "Epoch 477/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 598us/step - loss: 26.7185\n",
      "Epoch 478/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.0915\n",
      "Epoch 479/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.0616\n",
      "Epoch 480/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 27.3926\n",
      "Epoch 481/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.0184\n",
      "Epoch 482/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.0681\n",
      "Epoch 483/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.9393\n",
      "Epoch 484/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.5212\n",
      "Epoch 485/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.7631\n",
      "Epoch 486/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 26.2005\n",
      "Epoch 487/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.3344\n",
      "Epoch 488/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.5154\n",
      "Epoch 489/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.7103\n",
      "Epoch 490/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.9974\n",
      "Epoch 491/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.5638\n",
      "Epoch 492/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.8392\n",
      "Epoch 493/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.7759\n",
      "Epoch 494/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.1423\n",
      "Epoch 495/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.0201\n",
      "Epoch 496/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.9984\n",
      "Epoch 497/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.9458\n",
      "Epoch 498/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.9146\n",
      "Epoch 499/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.7602\n",
      "Epoch 500/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 23.8356\n",
      "Epoch 501/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.4825\n",
      "Epoch 502/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.4418\n",
      "Epoch 503/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.0723\n",
      "Epoch 504/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.5440\n",
      "Epoch 505/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.0481\n",
      "Epoch 506/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 26.8797\n",
      "Epoch 507/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.4803\n",
      "Epoch 508/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.8871\n",
      "Epoch 509/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.9959\n",
      "Epoch 510/1000\n",
      "16/16 [==============================] - 0s 467us/step - loss: 26.2173\n",
      "Epoch 511/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.7798\n",
      "Epoch 512/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.8388\n",
      "Epoch 513/1000\n",
      "16/16 [==============================] - 0s 467us/step - loss: 25.7749\n",
      "Epoch 514/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.5676\n",
      "Epoch 515/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.3389\n",
      "Epoch 516/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.1353\n",
      "Epoch 517/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.8900\n",
      "Epoch 518/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.7789\n",
      "Epoch 519/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.1482\n",
      "Epoch 520/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.0045\n",
      "Epoch 521/1000\n",
      "16/16 [==============================] - 0s 626us/step - loss: 26.4375\n",
      "Epoch 522/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.8150\n",
      "Epoch 523/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.5495\n",
      "Epoch 524/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.5780\n",
      "Epoch 525/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.3265\n",
      "Epoch 526/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.7857\n",
      "Epoch 527/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 25.8103\n",
      "Epoch 528/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 25.5683\n",
      "Epoch 529/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.0243\n",
      "Epoch 530/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.4355\n",
      "Epoch 531/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.0832\n",
      "Epoch 532/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.3301\n",
      "Epoch 533/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.5743\n",
      "Epoch 534/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.1213\n",
      "Epoch 535/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.6693\n",
      "Epoch 536/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.5001\n",
      "Epoch 537/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.1769\n",
      "Epoch 538/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.9213\n",
      "Epoch 539/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.0799\n",
      "Epoch 540/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.5995\n",
      "Epoch 541/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 26.3511\n",
      "Epoch 542/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.5477\n",
      "Epoch 543/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.6772\n",
      "Epoch 544/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.0684\n",
      "Epoch 545/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.0765\n",
      "Epoch 546/1000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 25.0284\n",
      "Epoch 547/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.6398\n",
      "Epoch 548/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.5868\n",
      "Epoch 549/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.5837\n",
      "Epoch 550/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.7972\n",
      "Epoch 551/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.7168\n",
      "Epoch 552/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 26.0767\n",
      "Epoch 553/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.4809\n",
      "Epoch 554/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.6785\n",
      "Epoch 555/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.4113\n",
      "Epoch 556/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.9590\n",
      "Epoch 557/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.7414\n",
      "Epoch 558/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.9214\n",
      "Epoch 559/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.8460\n",
      "Epoch 560/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.1704\n",
      "Epoch 561/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.2400\n",
      "Epoch 562/1000\n",
      "16/16 [==============================] - 0s 491us/step - loss: 26.6166\n",
      "Epoch 563/1000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 25.3106\n",
      "Epoch 564/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.8433\n",
      "Epoch 565/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.5101\n",
      "Epoch 566/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.9254\n",
      "Epoch 567/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 28.6779\n",
      "Epoch 568/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.6799\n",
      "Epoch 569/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 27.4094\n",
      "Epoch 570/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.3759\n",
      "Epoch 571/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.1102\n",
      "Epoch 572/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 598us/step - loss: 26.0303\n",
      "Epoch 573/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.8489\n",
      "Epoch 574/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.7035\n",
      "Epoch 575/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.1205\n",
      "Epoch 576/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 25.6056\n",
      "Epoch 577/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.2765\n",
      "Epoch 578/1000\n",
      "16/16 [==============================] - 0s 666us/step - loss: 24.9908\n",
      "Epoch 579/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.6471\n",
      "Epoch 580/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.9873\n",
      "Epoch 581/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.5437\n",
      "Epoch 582/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.0967\n",
      "Epoch 583/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.2252\n",
      "Epoch 584/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.2260\n",
      "Epoch 585/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.5595\n",
      "Epoch 586/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.1268\n",
      "Epoch 587/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.0326\n",
      "Epoch 588/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.0472\n",
      "Epoch 589/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.7517\n",
      "Epoch 590/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.0321\n",
      "Epoch 591/1000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 26.9843\n",
      "Epoch 592/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.8086\n",
      "Epoch 593/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.4072\n",
      "Epoch 594/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.2135\n",
      "Epoch 595/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.5356\n",
      "Epoch 596/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.0092\n",
      "Epoch 597/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.1655\n",
      "Epoch 598/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.1137\n",
      "Epoch 599/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.3341\n",
      "Epoch 600/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 26.8623\n",
      "Epoch 601/1000\n",
      "16/16 [==============================] - 0s 632us/step - loss: 24.7808\n",
      "Epoch 602/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.2784\n",
      "Epoch 603/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.2814\n",
      "Epoch 604/1000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 25.0279\n",
      "Epoch 605/1000\n",
      "16/16 [==============================] - 0s 399us/step - loss: 25.3565\n",
      "Epoch 606/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.8602\n",
      "Epoch 607/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.2597\n",
      "Epoch 608/1000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 24.9322\n",
      "Epoch 609/1000\n",
      "16/16 [==============================] - 0s 664us/step - loss: 27.8467\n",
      "Epoch 610/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.3976\n",
      "Epoch 611/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.4133\n",
      "Epoch 612/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.8934\n",
      "Epoch 613/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.7017\n",
      "Epoch 614/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.9547\n",
      "Epoch 615/1000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 27.4028\n",
      "Epoch 616/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.7419\n",
      "Epoch 617/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.2950\n",
      "Epoch 618/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.4899\n",
      "Epoch 619/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.8862\n",
      "Epoch 620/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.6384\n",
      "Epoch 621/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 25.6702\n",
      "Epoch 622/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.3735\n",
      "Epoch 623/1000\n",
      "16/16 [==============================] - 0s 399us/step - loss: 25.0315\n",
      "Epoch 624/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.8060\n",
      "Epoch 625/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.4328\n",
      "Epoch 626/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.9689\n",
      "Epoch 627/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.5866\n",
      "Epoch 628/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.8176\n",
      "Epoch 629/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 25.9181\n",
      "Epoch 630/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.0529\n",
      "Epoch 631/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.5658\n",
      "Epoch 632/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.5401\n",
      "Epoch 633/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 26.7137\n",
      "Epoch 634/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.2173\n",
      "Epoch 635/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.2997\n",
      "Epoch 636/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 25.4073\n",
      "Epoch 637/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.0829\n",
      "Epoch 638/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.8487\n",
      "Epoch 639/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.8837\n",
      "Epoch 640/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.9350\n",
      "Epoch 641/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.1401\n",
      "Epoch 642/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.3068\n",
      "Epoch 643/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.4536\n",
      "Epoch 644/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.9309\n",
      "Epoch 645/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.1012\n",
      "Epoch 646/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 27.0825\n",
      "Epoch 647/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.4280\n",
      "Epoch 648/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.5195\n",
      "Epoch 649/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.7881\n",
      "Epoch 650/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.9297\n",
      "Epoch 651/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 26.3276\n",
      "Epoch 652/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 37.11 - 0s 566us/step - loss: 26.1525\n",
      "Epoch 653/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.3633\n",
      "Epoch 654/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.0523\n",
      "Epoch 655/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.7797\n",
      "Epoch 656/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.5514\n",
      "Epoch 657/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.8868\n",
      "Epoch 658/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.2772\n",
      "Epoch 659/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.0181\n",
      "Epoch 660/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.3029\n",
      "Epoch 661/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.5174\n",
      "Epoch 662/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.4389\n",
      "Epoch 663/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.9319\n",
      "Epoch 664/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.2116\n",
      "Epoch 665/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.5420\n",
      "Epoch 666/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 23.7682\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 532us/step - loss: 27.4048\n",
      "Epoch 668/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.2560\n",
      "Epoch 669/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.2946\n",
      "Epoch 670/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.7578\n",
      "Epoch 671/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.1379\n",
      "Epoch 672/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.1096\n",
      "Epoch 673/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.6074\n",
      "Epoch 674/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.3984\n",
      "Epoch 675/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.5414\n",
      "Epoch 676/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.6010\n",
      "Epoch 677/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.1395\n",
      "Epoch 678/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.4217\n",
      "Epoch 679/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.7605\n",
      "Epoch 680/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.6623\n",
      "Epoch 681/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 24.4367\n",
      "Epoch 682/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.3874\n",
      "Epoch 683/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.2800\n",
      "Epoch 684/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.1828\n",
      "Epoch 685/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.7484\n",
      "Epoch 686/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.9671\n",
      "Epoch 687/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 26.1974\n",
      "Epoch 688/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 23.9185\n",
      "Epoch 689/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 25.3271\n",
      "Epoch 690/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.3133\n",
      "Epoch 691/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.0634\n",
      "Epoch 692/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.5366\n",
      "Epoch 693/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.0739\n",
      "Epoch 694/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.1382\n",
      "Epoch 695/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 25.6277\n",
      "Epoch 696/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 26.0611\n",
      "Epoch 697/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.0265\n",
      "Epoch 698/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.7002\n",
      "Epoch 699/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 27.3316\n",
      "Epoch 700/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 24.3667\n",
      "Epoch 701/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 27.1766\n",
      "Epoch 702/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.4509\n",
      "Epoch 703/1000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 22.5538\n",
      "Epoch 704/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 26.9256\n",
      "Epoch 705/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 25.0083\n",
      "Epoch 706/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 26.8123\n",
      "Epoch 707/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.7361\n",
      "Epoch 708/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 23.2494\n",
      "Epoch 709/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.9544\n",
      "Epoch 710/1000\n",
      "16/16 [==============================] - 0s 931us/step - loss: 24.7119\n",
      "Epoch 711/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 27.6567\n",
      "Epoch 712/1000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 24.7950\n",
      "Epoch 713/1000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 24.7177\n",
      "Epoch 714/1000\n",
      "16/16 [==============================] - 0s 998us/step - loss: 24.9543\n",
      "Epoch 715/1000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 25.4383\n",
      "Epoch 716/1000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 26.3991\n",
      "Epoch 717/1000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 26.4569\n",
      "Epoch 718/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 24.9144\n",
      "Epoch 719/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 27.3791\n",
      "Epoch 720/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.4950\n",
      "Epoch 721/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 26.5762\n",
      "Epoch 722/1000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 27.0169\n",
      "Epoch 723/1000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 24.1850\n",
      "Epoch 724/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.0491\n",
      "Epoch 725/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.5812\n",
      "Epoch 726/1000\n",
      "16/16 [==============================] - 0s 931us/step - loss: 24.4963\n",
      "Epoch 727/1000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 26.1727\n",
      "Epoch 728/1000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 23.4803\n",
      "Epoch 729/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 26.7788\n",
      "Epoch 730/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.0521\n",
      "Epoch 731/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.3011\n",
      "Epoch 732/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.7369\n",
      "Epoch 733/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.7633\n",
      "Epoch 734/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.3019\n",
      "Epoch 735/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.9341\n",
      "Epoch 736/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.8204\n",
      "Epoch 737/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.3571\n",
      "Epoch 738/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.5574\n",
      "Epoch 739/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.0687\n",
      "Epoch 740/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 24.2387\n",
      "Epoch 741/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.8807\n",
      "Epoch 742/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 27.0065\n",
      "Epoch 743/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.9299\n",
      "Epoch 744/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.9987\n",
      "Epoch 745/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.0792\n",
      "Epoch 746/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.3663\n",
      "Epoch 747/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.4401\n",
      "Epoch 748/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.8702\n",
      "Epoch 749/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.7120\n",
      "Epoch 750/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 28.0382\n",
      "Epoch 751/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 23.8764\n",
      "Epoch 752/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 27.0842\n",
      "Epoch 753/1000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 25.2416\n",
      "Epoch 754/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.8816\n",
      "Epoch 755/1000\n",
      "16/16 [==============================] - 0s 931us/step - loss: 25.0724\n",
      "Epoch 756/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 26.4041\n",
      "Epoch 757/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 24.7463\n",
      "Epoch 758/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 25.6684\n",
      "Epoch 759/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.9747\n",
      "Epoch 760/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.7581\n",
      "Epoch 761/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 27.4855\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 798us/step - loss: 23.7006\n",
      "Epoch 763/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 24.6929\n",
      "Epoch 764/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.7886\n",
      "Epoch 765/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.3828\n",
      "Epoch 766/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 24.3348\n",
      "Epoch 767/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.6153\n",
      "Epoch 768/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.5861\n",
      "Epoch 769/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.0819\n",
      "Epoch 770/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.1175\n",
      "Epoch 771/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.9200\n",
      "Epoch 772/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.9289\n",
      "Epoch 773/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.5677\n",
      "Epoch 774/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.9650\n",
      "Epoch 775/1000\n",
      "16/16 [==============================] - 0s 931us/step - loss: 23.9122\n",
      "Epoch 776/1000\n",
      "16/16 [==============================] - 0s 931us/step - loss: 24.7117\n",
      "Epoch 777/1000\n",
      "16/16 [==============================] - 0s 997us/step - loss: 25.2941\n",
      "Epoch 778/1000\n",
      "16/16 [==============================] - 0s 907us/step - loss: 27.1418\n",
      "Epoch 779/1000\n",
      "16/16 [==============================] - 0s 931us/step - loss: 23.1317\n",
      "Epoch 780/1000\n",
      "16/16 [==============================] - 0s 732us/step - loss: 23.7908\n",
      "Epoch 781/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.7087\n",
      "Epoch 782/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.9395\n",
      "Epoch 783/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 24.7615\n",
      "Epoch 784/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.2728\n",
      "Epoch 785/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 22.5591\n",
      "Epoch 786/1000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 25.9088\n",
      "Epoch 787/1000\n",
      "16/16 [==============================] - 0s 997us/step - loss: 24.3266\n",
      "Epoch 788/1000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 26.1671\n",
      "Epoch 789/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 23.5302\n",
      "Epoch 790/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 36.06 - 0s 465us/step - loss: 26.7133\n",
      "Epoch 791/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.4058\n",
      "Epoch 792/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 25.6831\n",
      "Epoch 793/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 24.7914\n",
      "Epoch 794/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.9407\n",
      "Epoch 795/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.1991\n",
      "Epoch 796/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.4397\n",
      "Epoch 797/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.7514\n",
      "Epoch 798/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 24.4244\n",
      "Epoch 799/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.2924\n",
      "Epoch 800/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.6850\n",
      "Epoch 801/1000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 25.2784\n",
      "Epoch 802/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.2841\n",
      "Epoch 803/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.2927\n",
      "Epoch 804/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 24.7668\n",
      "Epoch 805/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.9840\n",
      "Epoch 806/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.9509\n",
      "Epoch 807/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.4004\n",
      "Epoch 808/1000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 24.0558\n",
      "Epoch 809/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.3019\n",
      "Epoch 810/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.1740\n",
      "Epoch 811/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.4010\n",
      "Epoch 812/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.3002\n",
      "Epoch 813/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.0213\n",
      "Epoch 814/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 25.4555\n",
      "Epoch 815/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.7692\n",
      "Epoch 816/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.9246\n",
      "Epoch 817/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.5819\n",
      "Epoch 818/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.9565\n",
      "Epoch 819/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.8850\n",
      "Epoch 820/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.1423\n",
      "Epoch 821/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.8616\n",
      "Epoch 822/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 25.7726\n",
      "Epoch 823/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 27.7551\n",
      "Epoch 824/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 23.8502\n",
      "Epoch 825/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.0215\n",
      "Epoch 826/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.9127\n",
      "Epoch 827/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.7033\n",
      "Epoch 828/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.2813\n",
      "Epoch 829/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.1063\n",
      "Epoch 830/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.5310\n",
      "Epoch 831/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.6784\n",
      "Epoch 832/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.4678\n",
      "Epoch 833/1000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 27.9883\n",
      "Epoch 834/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.7427\n",
      "Epoch 835/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.6365\n",
      "Epoch 836/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.8199\n",
      "Epoch 837/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.9245\n",
      "Epoch 838/1000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 24.9905\n",
      "Epoch 839/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.5961\n",
      "Epoch 840/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.8914\n",
      "Epoch 841/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.7799\n",
      "Epoch 842/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.4463\n",
      "Epoch 843/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.4374\n",
      "Epoch 844/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.2633\n",
      "Epoch 845/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.3615\n",
      "Epoch 846/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.8378\n",
      "Epoch 847/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 29.0119\n",
      "Epoch 848/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.9668\n",
      "Epoch 849/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.5367\n",
      "Epoch 850/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.4869\n",
      "Epoch 851/1000\n",
      "16/16 [==============================] - 0s 612us/step - loss: 24.5935\n",
      "Epoch 852/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.2291\n",
      "Epoch 853/1000\n",
      "16/16 [==============================] - 0s 498us/step - loss: 25.4815\n",
      "Epoch 854/1000\n",
      "16/16 [==============================] - 0s 663us/step - loss: 24.7237\n",
      "Epoch 855/1000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 23.7478\n",
      "Epoch 856/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.1465\n",
      "Epoch 857/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 532us/step - loss: 24.3564\n",
      "Epoch 858/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.9241\n",
      "Epoch 859/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.7977\n",
      "Epoch 860/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 24.5558\n",
      "Epoch 861/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.7602\n",
      "Epoch 862/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.1863\n",
      "Epoch 863/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.8960\n",
      "Epoch 864/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.6555\n",
      "Epoch 865/1000\n",
      "16/16 [==============================] - 0s 666us/step - loss: 24.2690\n",
      "Epoch 866/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.5105\n",
      "Epoch 867/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.0634\n",
      "Epoch 868/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.3278\n",
      "Epoch 869/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 23.9863\n",
      "Epoch 870/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.0910\n",
      "Epoch 871/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.0645\n",
      "Epoch 872/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.5803\n",
      "Epoch 873/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.3653\n",
      "Epoch 874/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 23.5674\n",
      "Epoch 875/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.7714\n",
      "Epoch 876/1000\n",
      "16/16 [==============================] - 0s 732us/step - loss: 25.1956\n",
      "Epoch 877/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.5640\n",
      "Epoch 878/1000\n",
      "16/16 [==============================] - 0s 666us/step - loss: 23.7235\n",
      "Epoch 879/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.2047\n",
      "Epoch 880/1000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 24.3347\n",
      "Epoch 881/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 22.2327\n",
      "Epoch 882/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.8635\n",
      "Epoch 883/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.1684\n",
      "Epoch 884/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.3747\n",
      "Epoch 885/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 23.1062\n",
      "Epoch 886/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.4726\n",
      "Epoch 887/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 23.0449\n",
      "Epoch 888/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.1581\n",
      "Epoch 889/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.5783\n",
      "Epoch 890/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 23.3505\n",
      "Epoch 891/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.4591\n",
      "Epoch 892/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 23.9211\n",
      "Epoch 893/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.8935\n",
      "Epoch 894/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.4311\n",
      "Epoch 895/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 22.9236\n",
      "Epoch 896/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.2080\n",
      "Epoch 897/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.0018\n",
      "Epoch 898/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.8121\n",
      "Epoch 899/1000\n",
      "16/16 [==============================] - 0s 510us/step - loss: 23.9032\n",
      "Epoch 900/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.1596\n",
      "Epoch 901/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.5240\n",
      "Epoch 902/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.9713\n",
      "Epoch 903/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.5047\n",
      "Epoch 904/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.3273\n",
      "Epoch 905/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 24.1197\n",
      "Epoch 906/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.5941\n",
      "Epoch 907/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.9868\n",
      "Epoch 908/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.3849\n",
      "Epoch 909/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.8418\n",
      "Epoch 910/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.9946\n",
      "Epoch 911/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.0110\n",
      "Epoch 912/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 23.5106\n",
      "Epoch 913/1000\n",
      "16/16 [==============================] - 0s 399us/step - loss: 24.0221\n",
      "Epoch 914/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.9014\n",
      "Epoch 915/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.2231\n",
      "Epoch 916/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 23.6885\n",
      "Epoch 917/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.7709\n",
      "Epoch 918/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.3123\n",
      "Epoch 919/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 23.3634\n",
      "Epoch 920/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 22.8512\n",
      "Epoch 921/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.5233\n",
      "Epoch 922/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.6221\n",
      "Epoch 923/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.8668\n",
      "Epoch 924/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 25.2401\n",
      "Epoch 925/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.7716\n",
      "Epoch 926/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 23.9036\n",
      "Epoch 927/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 35.91 - 0s 532us/step - loss: 25.3559\n",
      "Epoch 928/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 22.8406\n",
      "Epoch 929/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.1479\n",
      "Epoch 930/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.4318\n",
      "Epoch 931/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.0620\n",
      "Epoch 932/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.3813\n",
      "Epoch 933/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.2661\n",
      "Epoch 934/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.9905\n",
      "Epoch 935/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.7827\n",
      "Epoch 936/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 22.6840\n",
      "Epoch 937/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.7620\n",
      "Epoch 938/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.5543\n",
      "Epoch 939/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.6740\n",
      "Epoch 940/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.4709\n",
      "Epoch 941/1000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 23.7883\n",
      "Epoch 942/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 22.3688\n",
      "Epoch 943/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.3796\n",
      "Epoch 944/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.0005\n",
      "Epoch 945/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 25.3542\n",
      "Epoch 946/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.3723\n",
      "Epoch 947/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.7258\n",
      "Epoch 948/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.1377\n",
      "Epoch 949/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 24.5413\n",
      "Epoch 950/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.3669\n",
      "Epoch 951/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.5154\n",
      "Epoch 952/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 532us/step - loss: 22.8608\n",
      "Epoch 953/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 23.7055\n",
      "Epoch 954/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.1733\n",
      "Epoch 955/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 25.8301\n",
      "Epoch 956/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.3191\n",
      "Epoch 957/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 23.7977\n",
      "Epoch 958/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.0607\n",
      "Epoch 959/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.8921\n",
      "Epoch 960/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.3684\n",
      "Epoch 961/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.0013\n",
      "Epoch 962/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 22.6787\n",
      "Epoch 963/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 26.0408\n",
      "Epoch 964/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.4037\n",
      "Epoch 965/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 26.1758\n",
      "Epoch 966/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.2478\n",
      "Epoch 967/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 22.4036\n",
      "Epoch 968/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 26.0622\n",
      "Epoch 969/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.6388\n",
      "Epoch 970/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 24.0644\n",
      "Epoch 971/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.2921\n",
      "Epoch 972/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.7542\n",
      "Epoch 973/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.6913\n",
      "Epoch 974/1000\n",
      "16/16 [==============================] - 0s 666us/step - loss: 24.9465\n",
      "Epoch 975/1000\n",
      "16/16 [==============================] - 0s 466us/step - loss: 22.6579\n",
      "Epoch 976/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.9795\n",
      "Epoch 977/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.3510\n",
      "Epoch 978/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 23.0129\n",
      "Epoch 979/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 24.1144\n",
      "Epoch 980/1000\n",
      "16/16 [==============================] - 0s 399us/step - loss: 23.7072\n",
      "Epoch 981/1000\n",
      "16/16 [==============================] - 0s 663us/step - loss: 22.3723\n",
      "Epoch 982/1000\n",
      "16/16 [==============================] - 0s 732us/step - loss: 24.7593\n",
      "Epoch 983/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 25.0898\n",
      "Epoch 984/1000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 23.8860\n",
      "Epoch 985/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.3483\n",
      "Epoch 986/1000\n",
      "16/16 [==============================] - 0s 732us/step - loss: 23.2480\n",
      "Epoch 987/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.9315\n",
      "Epoch 988/1000\n",
      "16/16 [==============================] - 0s 465us/step - loss: 24.4886\n",
      "Epoch 989/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 23.8551\n",
      "Epoch 990/1000\n",
      "16/16 [==============================] - 0s 732us/step - loss: 24.6886\n",
      "Epoch 991/1000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 23.9552\n",
      "Epoch 992/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 25.1967\n",
      "Epoch 993/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 23.1775\n",
      "Epoch 994/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 23.2602\n",
      "Epoch 995/1000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 22.1158\n",
      "Epoch 996/1000\n",
      "16/16 [==============================] - 0s 740us/step - loss: 26.2478\n",
      "Epoch 997/1000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 23.2533\n",
      "Epoch 998/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 26.3682\n",
      "Epoch 999/1000\n",
      "16/16 [==============================] - 0s 731us/step - loss: 23.5810\n",
      "Epoch 1000/1000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 24.1258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e39e0a2490>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################\n",
    "# 3.데이터로 모델을 학습(FIT)합니다.\n",
    "model.fit(독립, 종속, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29.833664]\n",
      " [24.374681]\n",
      " [29.876358]\n",
      " [29.246538]\n",
      " [28.619432]]\n",
      "   medv\n",
      "0  24.0\n",
      "1  21.6\n",
      "2  34.7\n",
      "3  33.4\n",
      "4  36.2\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# 4. 모델을 이용합니다\n",
    "print(model.predict(독립[:5]))\n",
    "print(종속[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 5.4836810e-01,  7.5690418e-01,  3.3075458e-01,  3.4811550e-01,\n",
      "         1.5534386e-01, -1.0516105e-01, -1.3540109e-01,  4.7399122e-02,\n",
      "        -2.8184464e-04, -5.4166931e-01],\n",
      "       [ 5.2945632e-01,  6.3528991e-03, -4.4696352e-01, -4.2128316e-01,\n",
      "         5.4626751e-01, -3.1920552e-01,  2.1758731e-01, -2.7476111e-01,\n",
      "        -9.7570501e-02,  1.4492826e-01],\n",
      "       [-3.3423847e-01, -2.5201336e-01, -1.3229540e-01, -6.0408674e-02,\n",
      "         7.0996845e-01,  3.1974831e-01, -4.0338603e-01,  4.8395172e-01,\n",
      "         3.3749866e-01, -1.1972142e-01],\n",
      "       [-1.1587809e+00,  9.2502612e-01,  2.0985776e-01, -2.1309092e+00,\n",
      "         2.4299593e+00, -9.3304086e-01,  1.0251403e+00,  1.1675785e+00,\n",
      "        -1.2158788e+00,  4.9478608e-01],\n",
      "       [ 3.5770881e-01,  1.2837386e-01,  1.8392849e-01,  8.3780360e-01,\n",
      "        -4.8842454e-01, -5.3534979e-01, -3.6877552e-01,  4.8193878e-01,\n",
      "        -4.7440401e-01, -3.3786741e-01],\n",
      "       [-1.4828697e+00, -2.5955713e-01, -1.2295917e-01,  1.1262369e+00,\n",
      "        -1.6574953e+00, -1.6790669e+00,  1.5439519e+00,  1.6498182e+00,\n",
      "        -1.6636025e+00,  1.7976811e+00],\n",
      "       [ 4.1251099e-01,  3.1062865e-03,  9.4247222e-02,  1.2661944e-01,\n",
      "         6.0650694e-01,  1.1843464e-03,  3.6644754e-01,  6.1013933e-02,\n",
      "         5.6467704e-02, -4.6469960e-01],\n",
      "       [ 8.0660713e-01, -1.2197524e-01, -4.1032049e-01,  6.0284072e-01,\n",
      "        -2.2287264e+00,  2.2407953e-01, -1.0049691e+00, -5.6174421e-01,\n",
      "         3.5427508e-01, -4.0612048e-01],\n",
      "       [-4.4887000e-01,  2.7801821e-01,  4.7490704e-01, -1.1705262e-02,\n",
      "        -7.0722061e-01,  2.0218465e-02, -3.3375588e-01,  7.0028925e-01,\n",
      "         2.6789136e-02, -7.4731312e-03],\n",
      "       [ 1.2981960e-01, -3.4631374e-01, -2.0437360e-01,  2.6370013e-01,\n",
      "         1.5970816e-01,  6.6158161e-02,  5.4800725e-01, -6.2101275e-02,\n",
      "         3.3319220e-01,  3.2790750e-01],\n",
      "       [ 2.1320353e-01, -2.9676703e-01, -2.9865617e-01,  2.8605191e-02,\n",
      "         1.1852983e-01,  7.5668997e-01,  6.0761388e-02,  1.5561980e-01,\n",
      "         4.0712029e-01, -6.0599697e-01],\n",
      "       [-9.9062942e-02,  1.8267277e-01, -3.5368401e-01, -4.1100433e-01,\n",
      "        -3.4115502e-01,  2.7021137e-01, -3.2334879e-01,  2.9446957e-01,\n",
      "        -7.2026044e-02,  2.3572160e-01],\n",
      "       [ 3.4113050e-01,  3.5067677e-02,  4.2198807e-01, -2.0804720e-01,\n",
      "        -9.4583756e-01,  1.4226721e-01, -3.1908429e-01, -2.2753531e-01,\n",
      "         1.3432847e-01, -2.5640905e-01]], dtype=float32), array([-0.6039718 , -0.10840448,  0.        , -0.58076334,  0.5270158 ,\n",
      "       -0.84108055,  0.84285897,  0.91505677, -0.85083014,  0.7941055 ],\n",
      "      dtype=float32), array([[-0.10807808],\n",
      "       [-8.895958  ],\n",
      "       [-0.6863102 ],\n",
      "       [-0.1824825 ],\n",
      "       [ 0.37002534],\n",
      "       [-0.6273017 ],\n",
      "       [ 0.25583145],\n",
      "       [ 0.75969094],\n",
      "       [-0.35355633],\n",
      "       [ 0.20418258]], dtype=float32), array([0.8284742], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# 모델의 수식 확인\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150, 3)\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# 1.과거의 데이터를 준비합니다.\n",
    "파일경로 = 'https://raw.githubusercontent.com/blackdew/tensorflow1/master/csv/iris.csv'\n",
    "아이리스 = pd.read_csv(파일경로)\n",
    " \n",
    "# 원핫인코딩\n",
    "아이리스 = pd.get_dummies(아이리스)\n",
    " \n",
    "# 종속변수, 독립변수\n",
    "독립 = 아이리스[['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭']]\n",
    "종속 = 아이리스[['품종_setosa', '품종_versicolor', '품종_virginica']]\n",
    "print(독립.shape, 종속.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# 2. 모델의 구조를 만듭니다\n",
    "X = tf.keras.layers.Input(shape=[4])\n",
    "H = tf.keras.layers.Dense(8, activation=\"swish\")(X)\n",
    "H = tf.keras.layers.Dense(8, activation=\"swish\")(H)\n",
    "H = tf.keras.layers.Dense(8, activation=\"swish\")(H)\n",
    "Y = tf.keras.layers.Dense(3, activation='softmax')(H)\n",
    "model = tf.keras.models.Model(X, Y)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics='accuracy')\n",
    " \n",
    "# 모델 구조 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 748us/step - loss: 1.0872 - accuracy: 0.6758\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0579 - accuracy: 0.6888\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0593 - accuracy: 0.6237\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0370 - accuracy: 0.6793\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 996us/step - loss: 1.0242 - accuracy: 0.6840\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0098 - accuracy: 0.6910\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9952 - accuracy: 0.6736\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9924 - accuracy: 0.6432\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.9725 - accuracy: 0.6462\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 734us/step - loss: 0.9522 - accuracy: 0.6857\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.9236 - accuracy: 0.6783\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 740us/step - loss: 0.9128 - accuracy: 0.6714\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9083 - accuracy: 0.6541\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8649 - accuracy: 0.6849\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8492 - accuracy: 0.6810\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8358 - accuracy: 0.6701\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.8244 - accuracy: 0.6682\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7865 - accuracy: 0.6993\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7598 - accuracy: 0.7317\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7277 - accuracy: 0.6902\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.7077 - accuracy: 0.7313\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6685 - accuracy: 0.7302\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.7931\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6656 - accuracy: 0.7877\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6172 - accuracy: 0.7757\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5936 - accuracy: 0.7946\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5809 - accuracy: 0.8659\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.8737\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5216 - accuracy: 0.8257\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5390 - accuracy: 0.8917\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.8165\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 747us/step - loss: 0.5114 - accuracy: 0.9038\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4633 - accuracy: 0.9360\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4425 - accuracy: 0.9292\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.9608\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.4401 - accuracy: 0.9723\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4248 - accuracy: 0.9435\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3972 - accuracy: 0.9680\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.3964 - accuracy: 0.9510\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3686 - accuracy: 0.9627\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3792 - accuracy: 0.9261\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3480 - accuracy: 0.9614\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3497 - accuracy: 0.9572\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3233 - accuracy: 0.9681\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3165 - accuracy: 0.9737\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3261 - accuracy: 0.9572\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2920 - accuracy: 0.9655\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2980 - accuracy: 0.9389\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2920 - accuracy: 0.9746\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 747us/step - loss: 0.2590 - accuracy: 0.9663\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 750us/step - loss: 0.2596 - accuracy: 0.9685\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2699 - accuracy: 0.9585\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2508 - accuracy: 0.9585\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 749us/step - loss: 0.2374 - accuracy: 0.9645\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2472 - accuracy: 0.9711\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2082 - accuracy: 0.9907\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2139 - accuracy: 0.9650\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2099 - accuracy: 0.9860\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2257 - accuracy: 0.9690\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2045 - accuracy: 0.9702\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9781\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.1985 - accuracy: 0.9532\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.1915 - accuracy: 0.9529\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1763 - accuracy: 0.9781\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.1660 - accuracy: 0.9777\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1588 - accuracy: 0.9650\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.1553 - accuracy: 0.9764\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.1485 - accuracy: 0.9855\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1422 - accuracy: 0.9807\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1317 - accuracy: 0.9864\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9655\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1397 - accuracy: 0.9545\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.1493 - accuracy: 0.9651\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.1288 - accuracy: 0.9851\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1370 - accuracy: 0.9624\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.1439 - accuracy: 0.9494\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1349 - accuracy: 0.9768\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1324 - accuracy: 0.9781\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.9690\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1286 - accuracy: 0.9641\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.1214 - accuracy: 0.9720\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.1338 - accuracy: 0.9686\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 996us/step - loss: 0.1088 - accuracy: 0.9720\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.1017 - accuracy: 0.9824\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0944 - accuracy: 0.9767\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.1338 - accuracy: 0.9441\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9733\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.1134 - accuracy: 0.9625\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.1050 - accuracy: 0.9637\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.1050 - accuracy: 0.9637\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.0898 - accuracy: 0.9907\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.0942 - accuracy: 0.9768\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0884 - accuracy: 0.9668\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 498us/step - loss: 0.1056 - accuracy: 0.9589\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.1014 - accuracy: 0.9712\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0888 - accuracy: 0.9694\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1021 - accuracy: 0.9772\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0826 - accuracy: 0.9777\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.0797 - accuracy: 0.9742\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.0704 - accuracy: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e39e187190>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################\n",
    "# 3.데이터로 모델을 학습(FIT)합니다.\n",
    "model.fit(독립, 종속, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9817884e-01 1.8208958e-03 1.9133728e-07]\n",
      " [9.9529845e-01 4.7007441e-03 7.9729858e-07]\n",
      " [9.9696857e-01 3.0310308e-03 5.1142325e-07]\n",
      " [9.9422437e-01 5.7746479e-03 9.7115696e-07]\n",
      " [9.9837625e-01 1.6235634e-03 1.6570446e-07]]\n",
      "   품종_setosa  품종_versicolor  품종_virginica\n",
      "0          1              0             0\n",
      "1          1              0             0\n",
      "2          1              0             0\n",
      "3          1              0             0\n",
      "4          1              0             0\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# 4. 모델을 이용합니다\n",
    "print(model.predict(독립[:5]))\n",
    "print(종속[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
